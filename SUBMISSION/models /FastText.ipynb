{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cd51cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tryptophanv2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re,string,unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import fasttext\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "nltk.download('stopwords')\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377c1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv(\"../Data/train.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c627c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse dataset -- In total : 28619 samples\n",
    "\n",
    "# get stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "#Apply function on headline column\n",
    "train_data['headline']=train_data['headline'].apply(denoise_text)\n",
    "test_data['headline']=test_data['headline'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04145ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'you better give dad good trade deal sorry!' shout angry trump boys phone employee local chinese restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>open letter graduation speakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump makes dubious claim inauguration singer jackie evancho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pope francis clarifies god one many immortal beings speak every day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>woman geared complain work sidelined friend marital problems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  \\\n",
       "0             1   \n",
       "1             0   \n",
       "2             0   \n",
       "3             1   \n",
       "4             1   \n",
       "\n",
       "                                                                                                      headline  \n",
       "0  'you better give dad good trade deal sorry!' shout angry trump boys phone employee local chinese restaurant  \n",
       "1                                                                              open letter graduation speakers  \n",
       "2                                          donald trump makes dubious claim inauguration singer jackie evancho  \n",
       "3                                          pope francis clarifies god one many immortal beings speak every day  \n",
       "4                                                 woman geared complain work sidelined friend marital problems  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c34b564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create fast text formatted \n",
    "def generate_txt_file(data,file_name):\n",
    "    for index, row in data.iterrows():\n",
    "        line = '__label__' + str(row['is_sarcastic']) + ' ' + row['headline']+'\\n'\n",
    "        with open(f'../Data/{file_name}','a') as out:\n",
    "            out.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "661c5ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate fast text formatted train and test data\n",
    "generate_txt_file(train_data,'fastTextTrain.txt')\n",
    "generate_txt_file(test_data,'fastTextTest.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ee803aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "model = fasttext.train_supervised(input=\"../Data/fastTextTrain.txt\",epoch=35,wordNgrams=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d6d2dc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predicted probabilities and their corresponding labels\n",
    "labels = []\n",
    "probs = []\n",
    "for headline in test_data['headline']:\n",
    "    label,prob = model.predict(headline)\n",
    "    labels.append(label)\n",
    "    probs.append(prob)\n",
    "    \n",
    "probs = [float(x[0]) for x in probs]\n",
    "labels = [int(x[0][9]) for x in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aff5b42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8106219426974144"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print accuracy\n",
    "acc(labels,test_data['is_sarcastic'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7e1c0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prediction probabilities for the class 1\n",
    "probs_for_1 = []\n",
    "for label,prob in zip(labels,probs):\n",
    "    if label == 0:\n",
    "        probs_for_1.append(1-prob)\n",
    "    else:\n",
    "        probs_for_1.append(prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "7496ad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dump prediction probabilities\n",
    "with open('./probs_for_1.pkl','wb') as f:\n",
    "    pickle.dump(probs_for_1,f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9387dfd027d85b4ef1fab9df2e45ec18d37a3040405152dfce86e72bba2a1fc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
