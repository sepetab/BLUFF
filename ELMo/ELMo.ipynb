{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22cd51cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/tryptophanv2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re,string,unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score as acc\n",
    "nltk.download('stopwords')\n",
    "pd.set_option('display.max_colwidth', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "377c1c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data\n",
    "train_data = pd.read_csv(\"../Data/train.csv\")\n",
    "test_data = pd.read_csv(\"../Data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c627c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parse dataset -- In total : 28619 samples\n",
    "\n",
    "# get stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "punctuation = list(string.punctuation)\n",
    "stop.update(punctuation)\n",
    "\n",
    "def strip_html(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    return soup.get_text()\n",
    "\n",
    "#Removing the square brackets\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub('\\[[^]]*\\]', '', text)\n",
    "\n",
    "# Removing URL's\n",
    "def remove_between_square_brackets(text):\n",
    "    return re.sub(r'http\\S+', '', text)\n",
    "\n",
    "#Removing the stopwords from text\n",
    "def remove_stopwords(text):\n",
    "    final_text = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stop:\n",
    "            final_text.append(i.strip())\n",
    "    return \" \".join(final_text)\n",
    "\n",
    "#Removing the noisy text\n",
    "def denoise_text(text):\n",
    "    text = strip_html(text)\n",
    "    text = remove_between_square_brackets(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text\n",
    "\n",
    "#Apply function on headline column\n",
    "train_data['headline']=train_data['headline'].apply(denoise_text)\n",
    "test_data['headline']=test_data['headline'].apply(denoise_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04145ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>'you better give dad good trade deal sorry!' shout angry trump boys phone employee local chinese restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>open letter graduation speakers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump makes dubious claim inauguration singer jackie evancho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pope francis clarifies god one many immortal beings speak every day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>woman geared complain work sidelined friend marital problems</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  \\\n",
       "0             1   \n",
       "1             0   \n",
       "2             0   \n",
       "3             1   \n",
       "4             1   \n",
       "\n",
       "                                                                                                      headline  \n",
       "0  'you better give dad good trade deal sorry!' shout angry trump boys phone employee local chinese restaurant  \n",
       "1                                                                              open letter graduation speakers  \n",
       "2                                          donald trump makes dubious claim inauguration singer jackie evancho  \n",
       "3                                          pope francis clarifies god one many immortal beings speak every day  \n",
       "4                                                 woman geared complain work sidelined friend marital problems  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7c52313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatize (normalize) the text by leveraging the popular spaCy library.\n",
    "\n",
    "\n",
    "# import spaCy's language model\n",
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "\n",
    "# function to lemmatize text\n",
    "def lemmatization(texts):\n",
    "    output = []\n",
    "    for i in texts:\n",
    "        s = [token.lemma_ for token in nlp(i)]\n",
    "        output.append(' '.join(s))\n",
    "    return output\n",
    "\n",
    "#lemmatize train and test data\n",
    "train_data['headline'] = lemmatization(train_data['headline'])\n",
    "test_data['headline'] = lemmatization(test_data['headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5ef51c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>is_sarcastic</th>\n",
       "      <th>headline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>' -PRON- well give dad good trade deal sorry ! ' shout angry trump boy phone employee local chinese restaurant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>open letter graduation speaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>donald trump make dubious claim inauguration singer jackie evancho</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>pope francis clarify god one many immortal being speak every day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>woman gear complain work sideline friend marital problem</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   is_sarcastic  \\\n",
       "0             1   \n",
       "1             0   \n",
       "2             0   \n",
       "3             1   \n",
       "4             1   \n",
       "\n",
       "                                                                                                         headline  \n",
       "0  ' -PRON- well give dad good trade deal sorry ! ' shout angry trump boy phone employee local chinese restaurant  \n",
       "1                                                                                  open letter graduation speaker  \n",
       "2                                              donald trump make dubious claim inauguration singer jackie evancho  \n",
       "3                                                pope francis clarify god one many immortal being speak every day  \n",
       "4                                                        woman gear complain work sideline friend marital problem  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0d115e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pretrained ELMO vectors\n",
    "elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=True)\n",
    "\n",
    "#Function to get elmo vectors for words in a string\n",
    "def elmo_vectors(x):\n",
    "  embeddings = elmo(x.tolist(), signature=\"default\", as_dict=True)[\"elmo\"]\n",
    "  with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.tables_initializer())\n",
    "    # return average of ELMo features\n",
    "    return sess.run(tf.reduce_mean(embeddings,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfc9175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################################################\n",
    "############################## ONLY RUN CELL IF ELMO EMBEDDED DATA ISNT AVAILABLE ################################\n",
    "##################################################################################################################\n",
    "\n",
    "\n",
    "\n",
    "# #Break training and test data down as using ELMO embeddings for all data at once will cause memory issues\n",
    "# list_train = [train_data[i:i+100] for i in range(0,train_data.shape[0],100)]\n",
    "# list_test = [test_data[i:i+100] for i in range(0,test_data.shape[0],100)]\n",
    "\n",
    "# # Extract ELMo embeddings\n",
    "# elmo_train = []\n",
    "# elmo_test = []\n",
    "# tr_len = len(list_train)\n",
    "# te_len = len(list_test)\n",
    "\n",
    "# for i,tr in enumerate(list_train):\n",
    "#     elmo_train.append(elmo_vectors(tr['headline']))\n",
    "#     print(f\"Processed {i}/{tr_len}\")\n",
    "# for i,te in enumerate(list_test):\n",
    "#     elmo_test.append(elmo_vectors(te['headline']))\n",
    "#     print(f\"Processed {i}/{te_len}\")\n",
    "\n",
    "# # Concatenate data back again\n",
    "# elmo_train_data = np.concatenate(elmo_train, axis = 0)\n",
    "# elmo_test_data = np.concatenate(elmo_test, axis = 0)\n",
    "# with open('elmo_train_data.pkl','wb') as f:\n",
    "#     pickle.dump(elmo_train_data, f)\n",
    "    \n",
    "# with open('elmo_test_data.pkl','wb') as f:\n",
    "#     pickle.dump(elmo_test_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa04990c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21464, 1024) (7155, 1024)\n"
     ]
    }
   ],
   "source": [
    "with open('../Data/elmo_train_data.pkl','rb') as f:\n",
    "    elmo_train_data = pickle.load(f)\n",
    "    \n",
    "with open('../Data/elmo_test_data.pkl','rb') as f:\n",
    "    elmo_test_data = pickle.load(f)\n",
    "\n",
    "print(elmo_train_data.shape,elmo_test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f499aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7905893314698346"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data for training and validating\n",
    "xtrain, xvalid, ytrain, yvalid = train_test_split(elmo_train_data, \n",
    "                                                  train_data['is_sarcastic'],  \n",
    "                                                  random_state=69, \n",
    "                                                  test_size=0.2)\n",
    "# Fit a logistic regression\n",
    "lreg = LogisticRegression(max_iter=2500)\n",
    "lreg.fit(xtrain, ytrain)\n",
    "\n",
    "# Get predictions\n",
    "preds_valid = lreg.predict(xvalid)\n",
    "acc(yvalid, preds_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cff4f36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7916142557651992"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What about the final test set?\n",
    "preds_test = lreg.predict(elmo_test_data)\n",
    "acc(preds_test,test_data['is_sarcastic'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31367428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.98625291 0.01374709]\n",
      " [0.69060755 0.30939245]\n",
      " [0.03140663 0.96859337]\n",
      " ...\n",
      " [0.02532157 0.97467843]\n",
      " [0.06298205 0.93701795]\n",
      " [0.18268463 0.81731537]]\n"
     ]
    }
   ],
   "source": [
    "# Output as predicted probabilites -- first column is 0 (not sarcastic) and second column is 1 (is sarcastic)\n",
    "print(lreg.predict_proba(elmo_test_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9387dfd027d85b4ef1fab9df2e45ec18d37a3040405152dfce86e72bba2a1fc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
